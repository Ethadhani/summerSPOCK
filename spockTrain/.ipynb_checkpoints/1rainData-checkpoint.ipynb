{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate SPOCK training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'featureKlassifier' from 'SPOCKalt' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../SPOCKalt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#Intigration/simsetup.py\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSPOCKalt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m featureKlassifier\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'featureKlassifier' from 'SPOCKalt' (unknown location)"
     ]
    }
   ],
   "source": [
    "import spock\n",
    "from spock import simsetup\n",
    "import random\n",
    "import numpy as np\n",
    "import rebound\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "#print(path)\n",
    "from SPOCKalt import *\n",
    "sys.path.insert(1, '../SPOCKalt')\n",
    "#Intigration/simsetup.py\n",
    "from SPOCKalt import featureKlassifier\n",
    "#from SPOCKalt import simsetup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the data path\n",
    "#We will be using cleaned data generated from the original spock initial conditions data, filtered according to https://github.com/Ethadhani/SPOCKcleanData.git\n",
    "datapath = '../../cleanData/csvs/resonant/'\n",
    "initial = pd.read_csv(datapath+'clean_initial_conditions.csv')\n",
    "labels = pd.read_csv(datapath+'clean_labels.csv')\n",
    "#drop junk column\n",
    "initial = initial.drop('Unnamed: 0', axis = 1)\n",
    "#merge labels and initial conditions based on runstring\n",
    "Initialdataset = initial.set_index('runstring').join(labels.set_index('runstring'))\n",
    "Initialdataset = Initialdataset.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can establish a function that, given a list of initial conditions, will return a rebound simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(row, dataset):\n",
    "    '''Given a row number, and a data sheet containing initial conditions, returns a corresponding simulation\n",
    "    \n",
    "        Arguments:\n",
    "            row: what row the simulation you would like to create is on\n",
    "                format of row is in order: \n",
    "                [index, 'p0m', 'p0x', 'p0y', 'p0z', 'p0vx', 'p0vy', 'p0vz', 'p1m', 'p1x', 'p1y',\n",
    "                'p1z', 'p1vx', 'p1vy', 'p1vz', 'p2m', 'p2x', 'p2y', 'p2z', 'p2vx',\n",
    "                'p2vy', 'p2vz', 'p3m', 'p3x', 'p3y', 'p3z', 'p3vx', 'p3vy', 'p3vz']\n",
    "\n",
    "            dataset: what dataset contains your initial conditions\n",
    "\n",
    "        return: returns a rebound simulation with the specified initial conditions'''\n",
    "    try:\n",
    "        data = dataset.loc[row]\n",
    "        sim = rebound.Simulation()\n",
    "        sim.G=4*np.pi**2\n",
    "        sim.add(m=data['p0m'], x=data['p0x'], y=data['p0y'], z=data['p0z'], vx=data['p0vx'], vy=data['p0vy'], vz=data['p0vz'])\n",
    "        sim.add(m=data['p1m'], x=data['p1x'], y=data['p1y'], z=data['p1z'], vx=data['p1vx'], vy=data['p1vy'], vz=data['p1vz'])\n",
    "        sim.add(m=data['p2m'], x=data['p2x'], y=data['p2y'], z=data['p2z'], vx=data['p2vx'], vy=data['p2vy'], vz=data['p2vz'])\n",
    "        sim.add(m=data['p3m'], x=data['p3x'], y=data['p3y'], z=data['p3z'], vx=data['p3vx'], vy=data['p3vy'], vz=data['p3vz'])\n",
    "        return sim\n",
    "    except:\n",
    "        print(\"Error reading initial condition {0}\".format(row))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate the set of system row indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates the indexes of the systems\n",
    "systemNum = range(Initialdataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note the column names and import the different feature generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = featureKlassifier.FeatureClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then establish some helper functions that will allow us to map the spock.generate_feature function to the different systems by mapping to different row numbers and generating the correct simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getList(features):\n",
    "    '''Helper function which isolates the data list from the generate_features return'''\n",
    "    return list(features[0][0].values())+[features[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeat(num):\n",
    "    '''when given a index of a row, loads initial conditions and returns the spock generated features'''\n",
    "    #gets features based on index num\n",
    "    sim = get_sim(num,initial)\n",
    "    return model.generate_features(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3.2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebound.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethadhani/summerSPOCK/spockTrain/../SPOCKalt/features.py:195: RuntimeWarning: invalid value encountered in log10\n",
      "  p2 = np.log10((ptot**(-1.5))*(1/(1-(ptot**(-1)))))\n",
      "/home/ethadhani/summerSPOCK/spockTrain/../SPOCKalt/features.py:196: RuntimeWarning: invalid value encountered in log\n",
      "  p3 = math.sqrt(-np.log(1-(ptot**(-1))))\n"
     ]
    }
   ],
   "source": [
    "col = list(getFeat(2)[0][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now map getFeat to the different rows of the Initial df, this will create each simulation and generate the spock features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from multiprocessing import Pool\n",
    "sys.path.append('spockUpdate/train_models')\n",
    "#import is required to get around jupyter notebook bug with multiprocessing\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool() as pool:\n",
    "        features = pool.map(getFeat,systemNum)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "#formats the data correctly\n",
    "formattedFeat = pd.DataFrame(np.array(list(map(getList,features))), columns = col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then join the generated features with the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.join(formattedFeat,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6631"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['MEGNO'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then save the new training data spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../modeldata/11grantData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
